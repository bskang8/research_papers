# arXiv Paper Briefing System

ë§¤ì¼ arXivì—ì„œ ë¡œë´‡/AI ë…¼ë¬¸ì„ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³ , AIë¡œ ë¶„ì„í•˜ì—¬ MongoDBì— ì €ì¥í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥

- **ìë™ ë…¼ë¬¸ ìˆ˜ì§‘**: arXiv APIë¡œ ì¡°ê±´ì— ë§ëŠ” ë…¼ë¬¸ ê²€ìƒ‰
- **AI íŠ¸ë¦¬ì•„ì§€**: OpenAI/Gemini APIë¡œ ë…¼ë¬¸ ìš”ì•½, íƒœê·¸ ë¶„ë¥˜, ì ìˆ˜ í‰ê°€
- **ì¸ìš©ìˆ˜ ì¶”ì **: Semantic Scholar APIë¡œ ì¸ìš©ìˆ˜ ìë™ ìˆ˜ì§‘
- **ì¤‘ë³µ ë°©ì§€**: MongoDB ê¸°ë°˜ ë…¼ë¬¸ ID ì¶”ì 
- **ë°ì´í„° ì €ì¥**: MongoDB + JSON ë¡œê·¸ íŒŒì¼

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

#### 1-1. í”„ë¡œì íŠ¸ í´ë¡  ë° ê°€ìƒí™˜ê²½ ìƒì„±

```bash
cd /home/bskang/papers
conda create -n Papers python=3.13
conda activate Papers
```

#### 1-2. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

**requirements.txt ë‚´ìš©:**
```
arxiv>=2.1.0
openai>=1.30.0
google-genai>=0.3.0
python-dotenv>=1.0.0
requests>=2.31.0
pyzotero>=1.5.0
pymongo>=4.6.0
```

### 2. MongoDB Docker ì»¨í…Œì´ë„ˆ ìƒì„±

#### 2-1. Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰

```bash
docker run -d \
  --name arxiv-mongodb \
  -p 27017:27017 \
  -v mongodb_data:/data/db \
  mongo:latest
```

**ì˜µì…˜ ì„¤ëª…:**
- `-d`: ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
- `--name arxiv-mongodb`: ì»¨í…Œì´ë„ˆ ì´ë¦„
- `-p 27017:27017`: í˜¸ìŠ¤íŠ¸ 27017 í¬íŠ¸ë¥¼ ì»¨í…Œì´ë„ˆ 27017ì— ë§¤í•‘ (ì™¸ë¶€ ì ‘ì† ê°€ëŠ¥)
- `-v mongodb_data:/data/db`: ë°ì´í„° ì˜êµ¬ ì €ì¥ (ë³¼ë¥¨)
- `mongo:latest`: MongoDB ìµœì‹  ì´ë¯¸ì§€

#### 2-2. MongoDB ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸

```bash
# ì‹¤í–‰ ì¤‘ì¸ MongoDB ì»¨í…Œì´ë„ˆ í™•ì¸
docker ps | grep mongo

# ì»¨í…Œì´ë„ˆ ë¡œê·¸ í™•ì¸
docker logs arxiv-mongodb

# MongoDB ë²„ì „ í™•ì¸
docker exec arxiv-mongodb mongosh --quiet --eval "db.version()"
```

#### 2-3. MongoDB ì»¨í…Œì´ë„ˆ ê´€ë¦¬ ëª…ë ¹ì–´

```bash
# ì»¨í…Œì´ë„ˆ ì‹œì‘
docker start arxiv-mongodb

# ì»¨í…Œì´ë„ˆ ì¤‘ì§€
docker stop arxiv-mongodb

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker restart arxiv-mongodb

# ì»¨í…Œì´ë„ˆ ì‚­ì œ (ë°ì´í„°ëŠ” ë³¼ë¥¨ì— ë³´ì¡´)
docker rm arxiv-mongodb

# ë°ì´í„°ê¹Œì§€ ì™„ì „ ì‚­ì œ
docker rm arxiv-mongodb
docker volume rm mongodb_data
```

### 3. API í‚¤ ì„¤ì •

#### 3-1. .env íŒŒì¼ ìƒì„±

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ `.env.example`ì„ ë³µì‚¬:

```bash
cp .env.example .env
nano .env
```

#### 3-2. .env íŒŒì¼ ë‚´ìš© ì‘ì„±

```bash
# â”€â”€ AI Provider ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# "openai" ë˜ëŠ” "gemini" ì„ íƒ
LLM_PROVIDER=gemini

# Gemini API Key (https://aistudio.google.com/app/apikey)
GEMINI_API_KEY=AIzaSyD_your_actual_key_here

# OpenAI API Key (https://platform.openai.com/api-keys)
# OPENAI_API_KEY=sk-your_openai_key_here

# â”€â”€ MongoDB ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MONGODB_URI=mongodb://localhost:27017/
MONGODB_DB_NAME=arxiv_papers
MONGODB_COLLECTION=papers

# â”€â”€ Slack (ì„ íƒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...

# â”€â”€ Zotero (ì„ íƒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ZOTERO_API_KEY=
# ZOTERO_USER_ID=
# ZOTERO_COLLECTION_KEY=
```

**API í‚¤ ë°œê¸‰ ë°©ë²•:**
- **Gemini**: https://aistudio.google.com/app/apikey
- **OpenAI**: https://platform.openai.com/api-keys

---

## ğŸ’» ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰

```bash
conda activate Papers
cd /home/bskang/papers

# ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python run_briefing.py

# Slack/Zotero ì „ì†¡ ì—†ì´ ê²°ê³¼ë§Œ í™•ì¸ (í…ŒìŠ¤íŠ¸ìš©)
python run_briefing.py --dry-run

# MongoDB ì´ˆê¸°í™” í›„ ì‹¤í–‰
python run_briefing.py --reset --dry-run

# Zotero ì €ì¥ ê±´ë„ˆë›°ê¸°
python run_briefing.py --no-zotero
```

### ì‹¤í–‰ ë‹¨ê³„ ì„¤ëª…

```
1. MongoDBì—ì„œ ì´ë¯¸ ì²˜ë¦¬ëœ ë…¼ë¬¸ ID ë¡œë“œ (ì¤‘ë³µ ë°©ì§€)
   â†“
2. arXiv APIë¡œ ë…¼ë¬¸ ìˆ˜ì§‘ (ì—°ë„ë³„ 100í¸ì”©)
   - ìµœê·¼: 6í¸ / 1ë…„ì „: 9í¸ / 2ë…„ì „: 6í¸ / 3~4ë…„ì „: 9í¸
   â†“
3. ì¤‘ë³µ í•„í„°ë§ ë° í•™íšŒì§€ ìš°ì„ ìˆœìœ„ ì •ë ¬
   â†“
4. Semantic Scholarì—ì„œ ì¸ìš©ìˆ˜ ì¡°íšŒ
   â†“
5. AI íŠ¸ë¦¬ì•„ì§€ (OpenAI/Gemini)
   - 3-5ë¬¸ì¥ í•œê¸€ ìš”ì•½
   - íƒœê·¸ ë¶„ë¥˜ (AD, VLA, Manipulation, Sim, Safety)
   - ê´€ë ¨ì„± ì ìˆ˜ (0~5)
   â†“
6. ë¡œê·¸ íŒŒì¼ ì €ì¥ (logs/YYYY-MM-DD.json)
   â†“
7. MongoDBì— ì €ì¥ (id, title, summary, citation_count, saved_at ë“±)
   â†“
8. (ì„ íƒ) Slack ì „ì†¡
   â†“
9. (ì„ íƒ) Zotero ì €ì¥ (ì ìˆ˜ 4.0 ì´ìƒ)
```

---

## ğŸ—„ï¸ MongoDB ë°ì´í„° ê´€ë¦¬

### MongoDB Shellë¡œ í™•ì¸

```bash
# MongoDB Shell ì ‘ì†
docker exec -it arxiv-mongodb mongosh arxiv_papers

# Shell ë‚´ë¶€ì—ì„œ ëª…ë ¹ ì‹¤í–‰
db.papers.countDocuments()                        # ì „ì²´ ë…¼ë¬¸ ìˆ˜
db.papers.find().limit(5)                         # ìµœê·¼ 5ê°œ ë…¼ë¬¸
db.papers.distinct("id")                          # ëª¨ë“  ë…¼ë¬¸ ID
db.papers.find({score: {$gte: 4.0}})             # ì ìˆ˜ 4.0 ì´ìƒ
db.papers.find({citation_count: {$gt: 0}})       # ì¸ìš©ìˆ˜ ìˆëŠ” ë…¼ë¬¸
db.papers.find({saved_at: {$regex: "^2026-02"}}) # 2ì›”ì— ì €ì¥ëœ ë…¼ë¬¸
```

### Pythonìœ¼ë¡œ í™•ì¸

```bash
# ì „ì²´ ë…¼ë¬¸ ìˆ˜
python -c "from paper_briefing.state import load_seen; print(f'ì´ {len(load_seen())}í¸')"

# ì¸ìš©ìˆ˜ ìƒìœ„ 10ê°œ
python -c "
from pymongo import MongoClient
client = MongoClient('mongodb://localhost:27017/')
collection = client['arxiv_papers']['papers']

print('ì¸ìš©ìˆ˜ TOP 10:')
for p in collection.find().sort('citation_count', -1).limit(10):
    print(f\"  [{p['citation_count']:3d} ì¸ìš©] {p['title'][:50]}\")
"

# ì˜¤ëŠ˜ ì €ì¥ëœ ë…¼ë¬¸
python -c "
from pymongo import MongoClient
from datetime import datetime
client = MongoClient('mongodb://localhost:27017/')
collection = client['arxiv_papers']['papers']

today = datetime.now().strftime('%Y-%m-%d')
count = collection.count_documents({'saved_at': {'\$regex': f'^{today}'}})
print(f'ì˜¤ëŠ˜({today}) ì €ì¥: {count}í¸')
"
```

### MongoDB ë°ì´í„° ì‚­ì œ

```bash
# í”„ë¡œê·¸ë¨ì˜ reset ì˜µì…˜ ì‚¬ìš© (ì¶”ì²œ)
python run_briefing.py --reset --dry-run

# Pythonìœ¼ë¡œ ì§ì ‘ ì‚­ì œ
python -c "from paper_briefing.state import reset_database; reset_database()"

# mongoshë¡œ ì§ì ‘ ì‚­ì œ
docker exec -it arxiv-mongodb mongosh arxiv_papers --eval "db.papers.deleteMany({})"

# íŠ¹ì • ì¡°ê±´ ì‚­ì œ (ì˜ˆ: Score 0ì¸ ë…¼ë¬¸)
docker exec -it arxiv-mongodb mongosh arxiv_papers --eval "db.papers.deleteMany({score: 0.0})"
```



## ğŸ“Š ë°ì´í„° êµ¬ì¡°

### MongoDB Document ìŠ¤í‚¤ë§ˆ

```javascript
{
  "id": "2401.12345v1",              // arXiv ID (ê³ ìœ  í‚¤)
  "title": "Paper Title",             // ë…¼ë¬¸ ì œëª©
  "abstract": "Full abstract...",     // ì´ˆë¡
  "authors": ["Author1", "Author2"],  // ì €ì ëª©ë¡ (ìµœëŒ€ 3ëª…)
  "published": "2024-01-15",          // ë…¼ë¬¸ ë°œí‘œì¼
  "arxiv_url": "http://arxiv.org/abs/2401.12345v1",
  "pdf_url": "https://arxiv.org/pdf/2401.12345v1",
  "categories": ["cs.RO", "cs.LG"],   // arXiv ì¹´í…Œê³ ë¦¬
  "journal_ref": "NeurIPS 2024",      // í•™íšŒì§€ ì •ë³´
  "comment": "Accepted at ...",       // ì½”ë©˜íŠ¸
  "conference": "NeurIPS",            // ì¶”ì¶œëœ í•™íšŒëª…
  "citation_count": 14,               // Semantic Scholar ì¸ìš©ìˆ˜
  "summary": "3-5ë¬¸ì¥ í•œê¸€ ìš”ì•½...",  // AI ìƒì„± ìš”ì•½
  "tags": ["VLA", "Manipulation"],    // AI ë¶„ë¥˜ íƒœê·¸
  "score": 4.5,                       // AI í‰ê°€ ì ìˆ˜ (0-5)
  "saved_at": "2026-02-23T14:18:19.123456"  // ì €ì¥ ì‹œê°
}
```

### ë¡œê·¸ íŒŒì¼ (logs/YYYY-MM-DD.json)

ë§¤ì¼ ì‹¤í–‰ ì‹œ í•´ë‹¹ ë‚ ì§œì˜ JSON íŒŒì¼ì— ì²˜ë¦¬ëœ ë…¼ë¬¸ ëª©ë¡ ì €ì¥:
- ê°™ì€ ë‚  ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ë©´ ë§ˆì§€ë§‰ ì‹¤í–‰ ê²°ê³¼ë¡œ ë®ì–´ì”Œì›Œì§
- MongoDBì™€ ë™ì¼í•œ ì •ë³´ í¬í•¨

---

## âš™ï¸ ì„¤ì • íŒŒì¼ (config.py)

ì£¼ìš” ì„¤ì •ê°’ë“¤:

```python
# arXiv ê²€ìƒ‰ ì¹´í…Œê³ ë¦¬
ARXIV_CATEGORIES = ["cs.RO", "cs.CV", "cs.LG", "cs.AI"]

# ì£¼ì œ í‚¤ì›Œë“œ (5ê°œ ì£¼ì œ)
TOPIC_KEYWORDS = {
    "AD": ["autonomous driving", "self-driving", ...],
    "VLA": ["vision-language-action", "VLA", ...],
    "Manipulation": ["manipulation", "dexterous", ...],
    "Sim": ["sim-to-real", "simulation", ...],
    "Safety": ["safety", "verification", ...],
}

# ìˆ˜ì§‘/ì²˜ë¦¬ ìˆ˜ëŸ‰
MAX_FETCH = 60      # arXiv í›„ë³´ ìˆ˜
MAX_PROCESS = 30    # ìµœì¢… ì²˜ë¦¬ ëŒ€ìƒ (í• ë‹¹ëŸ‰: 6+9+6+9=30)

# AI ì„¤ì •
LLM_PROVIDER = "gemini"  # "openai" or "gemini"
OPENAI_MODEL = "gpt-4o-mini"
GEMINI_MODEL = "models/gemini-2.5-flash"
TRIAGE_BATCH = 10   # ë°°ì¹˜ë‹¹ ë…¼ë¬¸ ìˆ˜
```

---

## ğŸ” ë…¼ë¬¸ ìˆ˜ì§‘ ë¡œì§

### ì—°ë„ë³„ í• ë‹¹ëŸ‰

- **ìµœê·¼ (2026ë…„)**: 6í¸
- **1ë…„ì „ (2025ë…„)**: 9í¸
- **2ë…„ì „ (2024ë…„)**: 6í¸
- **3~4ë…„ì „ (2022~2023ë…„)**: 9í¸
- **ì´ 30í¸**

### ìˆ˜ì§‘ ê³¼ì •

ê° ì—°ë„ë³„ë¡œ:
1. **ìˆ˜ì§‘**: arXivì—ì„œ ìµœëŒ€ 100í¸ ë‹¤ìš´ë¡œë“œ
2. **ì •ë ¬**: ì£¼ìš” í•™íšŒì§€(NeurIPS, CVPR, ICML ë“±) ìš°ì„ ìˆœìœ„
3. **ì¤‘ë³µ í•„í„°ë§**: MongoDBì— ì´ë¯¸ ìˆëŠ” ë…¼ë¬¸ ID ì œì™¸
4. **ì„ íƒ**: í• ë‹¹ëŸ‰ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ìˆœì°¨ ì„ íƒ

---

## ğŸ“ˆ ì¸ìš©ìˆ˜ ì¶”ì¶œ (Semantic Scholar)

### ë™ì‘ ë°©ì‹

1. arXiv IDë¡œ Semantic Scholar API í˜¸ì¶œ
2. ê° ë…¼ë¬¸ë§ˆë‹¤ 0.1ì´ˆ ì§€ì—° (rate limit ì¤€ìˆ˜)
3. 404 ì‘ë‹µ ì‹œ 0ìœ¼ë¡œ ì²˜ë¦¬ (ì•„ì§ ì¸ë±ì‹± ì•ˆ ëœ ìµœì‹  ë…¼ë¬¸)

### API ì„¸ë¶€ì‚¬í•­

- **Endpoint**: `https://api.semanticscholar.org/graph/v1/paper/ARXIV:{id}`
- **ë¬´ë£Œ**: API í‚¤ ë¶ˆí•„ìš”
- **Rate Limit**: ë¶„ë‹¹ 100 ìš”ì²­ (30í¸ = ì•½ 3ì´ˆ ì†Œìš”)

### ì½”ë“œ ìœ„ì¹˜

```python
# paper_briefing/arxiv_fetcher.py
def fetch_citation_count(arxiv_id: str) -> int
def fetch_citations_batch(papers: List[Paper], delay: float = 0.1) -> None
```

---

## ğŸ¤– AI íŠ¸ë¦¬ì•„ì§€

### OpenAI ì‚¬ìš©

```bash
# .env íŒŒì¼
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-...
```

**ëª¨ë¸**: `gpt-4o-mini` (ì €ë ´í•˜ê³  ë¹ ë¦„)

### Gemini ì‚¬ìš©

```bash
# .env íŒŒì¼
LLM_PROVIDER=gemini
GEMINI_API_KEY=AIzaSy...
```

**ëª¨ë¸**: `models/gemini-2.5-flash` (ìµœì‹ , ì•ˆì •ì )

### AIê°€ ìƒì„±í•˜ëŠ” ì •ë³´

ê° ë…¼ë¬¸ë§ˆë‹¤:
- **summary**: 3-5ë¬¸ì¥ í•œê¸€ ìš”ì•½ (ë¬¸ì œ, ë°©ë²•ë¡ , ê²°ê³¼, ì˜ì˜)
- **tags**: 1-3ê°œ íƒœê·¸ (AD, VLA, Manipulation, Sim, Safety)
- **score**: 0~5ì  (ììœ¨ì£¼í–‰/VLA/ë¡œë´‡/sim2real/ì•ˆì „ì„± ê´€ë ¨ì„±)

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
/home/bskang/papers/
â”œâ”€â”€ .env                    # API í‚¤ ë° í™˜ê²½ë³€ìˆ˜ (Git ì œì™¸)
â”œâ”€â”€ .env.example            # í™˜ê²½ë³€ìˆ˜ í…œí”Œë¦¿
â”œâ”€â”€ requirements.txt        # Python íŒ¨í‚¤ì§€
â”œâ”€â”€ run_briefing.py         # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ setup_cron.sh           # cron ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ concept.md              # í”„ë¡œì íŠ¸ ì»¨ì…‰ ë¬¸ì„œ
â”œâ”€â”€ README.md               # ì´ íŒŒì¼
â”‚
â”œâ”€â”€ paper_briefing/         # í•µì‹¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # ì¤‘ì•™ ì„¤ì • (í‚¤ì›Œë“œ, ëª¨ë¸ ë“±)
â”‚   â”œâ”€â”€ arxiv_fetcher.py    # arXiv ìˆ˜ì§‘ + ì¸ìš©ìˆ˜ ì¡°íšŒ
â”‚   â”œâ”€â”€ triage.py           # AI íŠ¸ë¦¬ì•„ì§€ (OpenAI/Gemini)
â”‚   â”œâ”€â”€ state.py            # MongoDB ê´€ë¦¬
â”‚   â”œâ”€â”€ logger.py           # JSON ë¡œê·¸ ì €ì¥
â”‚   â”œâ”€â”€ slack_sender.py     # Slack ì „ì†¡
â”‚   â””â”€â”€ zotero_saver.py     # Zotero ì €ì¥
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ seen_papers.json    # (ë ˆê±°ì‹œ) ì²˜ë¦¬ëœ ë…¼ë¬¸ ID
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ YYYY-MM-DD.json     # ì¼ë³„ ì‹¤í–‰ ë¡œê·¸
â”‚
â””â”€â”€ test_*.py               # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### MongoDB ì—°ê²° ì‹¤íŒ¨

```bash
# Docker ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker ps | grep mongo

# ì»¨í…Œì´ë„ˆê°€ ì—†ìœ¼ë©´ ì‹œì‘
docker start arxiv-mongodb

# ë¡œê·¸ í™•ì¸
docker logs arxiv-mongodb --tail 50

# Pythonìœ¼ë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
python -c "from pymongo import MongoClient; client = MongoClient('mongodb://localhost:27017/'); print('ì—°ê²° ì„±ê³µ:', client.server_info()['version'])"
```

### Gemini API ì˜¤ë¥˜

```bash
# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
python -c "
from google import genai
from dotenv import load_dotenv
import os

load_dotenv()
client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))
models = [m.name for m in client.models.list() if 'gemini' in m.name.lower()]
print('ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:')
for m in models[:10]:
    print(f'  - {m}')
"

# íŒ¨í‚¤ì§€ í™•ì¸
pip list | grep genai
```

### ì¸ìš©ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨

```bash
# Semantic Scholar API í…ŒìŠ¤íŠ¸
curl "https://api.semanticscholar.org/graph/v1/paper/ARXIV:2401.12345?fields=citationCount"

# Pythonìœ¼ë¡œ í…ŒìŠ¤íŠ¸
python -c "
from paper_briefing.arxiv_fetcher import fetch_citation_count
count = fetch_citation_count('2401.12345v1')
print(f'ì¸ìš©ìˆ˜: {count}')
"
```

### ìºì‹œ ë¬¸ì œ

```bash
# Python ìºì‹œ ì‚­ì œ
find . -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null
find . -name "*.pyc" -delete
```

---

## ğŸ“Š ë°ì´í„° ë¶„ì„ ì˜ˆì œ

### MongoDB ì¿¼ë¦¬ ì˜ˆì œ

```javascript
// íƒœê·¸ë³„ ë…¼ë¬¸ ìˆ˜
db.papers.aggregate([
  {$unwind: "$tags"},
  {$group: {_id: "$tags", count: {$sum: 1}}},
  {$sort: {count: -1}}
])

// Scoreì™€ ì¸ìš©ìˆ˜ ìƒê´€ê´€ê³„
db.papers.find({
  score: {$gte: 4.0},
  citation_count: {$gte: 5}
}, {
  title: 1,
  score: 1,
  citation_count: 1
}).sort({score: -1})

// í•™íšŒì§€ë³„ ë…¼ë¬¸ ìˆ˜
db.papers.aggregate([
  {$match: {conference: {$ne: ""}}},
  {$group: {_id: "$conference", count: {$sum: 1}}},
  {$sort: {count: -1}}
])

// ìµœê·¼ 30ì¼ ë…¼ë¬¸ ì¶”ì´
db.papers.aggregate([
  {$project: {
    date: {$substr: ["$saved_at", 0, 10]}
  }},
  {$group: {
    _id: "$date",
    count: {$sum: 1}
  }},
  {$sort: {_id: -1}},
  {$limit: 30}
])
```

---

## ğŸ”„ ìë™í™” (Cron)

ë§¤ì¼ ìë™ ì‹¤í–‰í•˜ë ¤ë©´:

```bash
# cron ì„¤ì • ì‹¤í–‰
bash setup_cron.sh

# ë˜ëŠ” ì§ì ‘ crontab í¸ì§‘
crontab -e

# ì¶”ê°€í•  ë‚´ìš© (ë§¤ì¼ ì˜¤ì „ 9ì‹œ ì‹¤í–‰)
0 9 * * * cd /home/bskang/papers && /home/bskang/miniconda3/envs/Papers/bin/python run_briefing.py
```

---

## ğŸ“ ë¡œê·¸ íŒŒì¼ í˜•ì‹

`logs/2026-02-23.json`:

```json
[
  {
    "id": "2401.12345v1",
    "title": "Paper Title",
    "score": 4.5,
    "tags": ["VLA", "Manipulation"],
    "summary": "3-5ë¬¸ì¥ì˜ í•œê¸€ ìš”ì•½...",
    "authors": ["Author1", "Author2"],
    "published": "2024-01-15",
    "citation_count": 14,
    "arxiv_url": "http://arxiv.org/abs/2401.12345v1",
    "pdf_url": "https://arxiv.org/pdf/2401.12345v1"
  }
]
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸

```bash
# arXiv ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
python test_fetch.py

# MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸
python test_mongodb.py

# í•™íšŒì§€ í•„í„° í…ŒìŠ¤íŠ¸
python test_conference_filter.py

# ì¡°ê±´ ì„ íƒ í…ŒìŠ¤íŠ¸
python test_criteria.py
```

---

## ğŸ¯ ì£¼ìš” ëª…ë ¹ì–´ ìš”ì•½

```bash
# === ì‹¤í–‰ ===
python run_briefing.py                    # ì „ì²´ ì‹¤í–‰
python run_briefing.py --dry-run          # í…ŒìŠ¤íŠ¸ (Slack/Zotero ì œì™¸)
python run_briefing.py --reset --dry-run  # MongoDB ì´ˆê¸°í™” í›„ ì‹¤í–‰

# === MongoDB Docker ===
docker ps | grep mongo                    # ìƒíƒœ í™•ì¸
docker start arxiv-mongodb                # ì‹œì‘
docker stop arxiv-mongodb                 # ì¤‘ì§€
docker logs arxiv-mongodb                 # ë¡œê·¸
docker exec -it arxiv-mongodb mongosh     # Shell ì ‘ì†

# === ë°ì´í„° í™•ì¸ ===
python -c "from paper_briefing.state import load_seen; print(len(load_seen()))"
docker exec arxiv-mongodb mongosh arxiv_papers --eval "db.papers.countDocuments()"

# === ë°ì´í„° ì‚­ì œ ===
python -c "from paper_briefing.state import reset_database; reset_database()"
docker exec -it arxiv-mongodb mongosh arxiv_papers --eval "db.papers.deleteMany({})"
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [arXiv API](https://info.arxiv.org/help/api/index.html)
- [Semantic Scholar API](https://api.semanticscholar.org/)
- [OpenAI API](https://platform.openai.com/docs)
- [Google Gemini API](https://ai.google.dev/)
- [MongoDB Manual](https://www.mongodb.com/docs/manual/)
- [DBeaver](https://dbeaver.io/)

---

## ğŸ’¡ íŒ

### ë¹„ìš© ì ˆê°
- Gemini 2.5 FlashëŠ” ë¬´ë£Œ í• ë‹¹ëŸ‰ì´ í¬ê³  ë¹ ë¦„ (ì¶”ì²œ)
- OpenAI gpt-4o-miniëŠ” ì €ë ´ (30í¸ = ì•½ $0.05)

### ì„±ëŠ¥ ìµœì í™”
- `TRIAGE_BATCH` ì¡°ì • (ê¸°ë³¸: 10í¸/ë°°ì¹˜)
- ì¸ìš©ìˆ˜ ì¡°íšŒ ì§€ì—° ì‹œê°„ ì¡°ì • (`delay=0.1`)

### ë°ì´í„° ë°±ì—…
```bash
# MongoDB ë°±ì—…
docker exec arxiv-mongodb mongodump --db arxiv_papers --out /tmp/backup

# ë³¼ë¥¨ ë°±ì—…
docker run --rm -v mongodb_data:/data -v $(pwd):/backup ubuntu tar czf /backup/mongodb_backup.tar.gz /data
```

---

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ë©´:
1. ë¡œê·¸ í™•ì¸: `docker logs arxiv-mongodb`
2. Python ì˜¤ë¥˜: í„°ë¯¸ë„ ì¶œë ¥ í™•ì¸
3. API í•œë„: API í‚¤ ë° í• ë‹¹ëŸ‰ í™•ì¸

---

**Last Updated**: 2026-02-23
